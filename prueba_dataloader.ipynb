{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "from tsl import logger\n",
    "from tsl.data import ImputationDataset, SpatioTemporalDataModule\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "from tsl.datasets import MetrLA, PemsBay, AirQuality\n",
    "from electric_data import ElectricData\n",
    "from tsl.engines import Imputer\n",
    "from tsl.experiment import Experiment\n",
    "from tsl.metrics import torch as torch_metrics, numpy as numpy_metrics\n",
    "from tsl.nn.models import RNNImputerModel, BiRNNImputerModel, GRINModel\n",
    "from tsl.ops.imputation import add_missing_values\n",
    "from tsl.transforms import MaskInput\n",
    "from tsl.utils.casting import torch_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MissingValueselectric(length=2208, n_nodes=6, n_channels=1)\n",
      "Sampling period: None\n",
      "Has missing values: True\n",
      "Percentage of missing values: 0.00%\n",
      "Percentage of missing values val: 9.10%\n",
      "Has dataset exogenous variables: True\n",
      "Relevant attributes: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_fault, p_noise = 0.0015, 0.05\n",
    "dataset = add_missing_values(ElectricData(normalized=True), p_fault=p_fault, p_noise=p_noise, min_seq=12, max_seq=12 * 4, seed=56789)\n",
    "\n",
    "print(f'\\n\\n{dataset}')\n",
    "print(f\"Sampling period: {dataset.freq}\\n\"\n",
    "      f\"Has missing values: {dataset.has_mask}\\n\"\n",
    "      f\"Percentage of missing values: {(1 - dataset.mask.mean()) * 100:.2f}%\\n\"\n",
    "      f\"Percentage of missing values val: {(dataset.eval_mask.mean()) * 100:.2f}%\\n\"\n",
    "      f\"Has dataset exogenous variables: {dataset.has_covariates}\\n\"\n",
    "      f\"Relevant attributes: {', '.join(dataset.attributes.keys())}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# get adjacency matrix\n",
    "adj = dataset.get_connectivity('pearson')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "torch_dataset = ImputationDataset(target=dataset.dataframe(),\n",
    "                                      eval_mask=dataset.eval_mask,\n",
    "                                      input_mask=dataset.training_mask,\n",
    "                                      transform=MaskInput(),\n",
    "                                      connectivity=adj,\n",
    "                                      window=24,\n",
    "                                      stride=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[], batch_size=32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers = {\n",
    "    'target': StandardScaler(axis=(0, 1))\n",
    "}\n",
    "splitter = dataset.get_splitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    #scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=32,\n",
    "    workers=0\n",
    ")\n",
    "dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "SpatioTemporalDataModule(train_len=1550, val_len=150, test_len=437, scalers=[], batch_size=32)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.setup()\n",
    "dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train = dm.train_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 StaticBatch(\n",
      "  input=(x=[b=32, t=24, n=6, f=1], input_mask=[b=32, t=24, n=6, f=1], edge_index=[2, e=36], edge_weight=[e=36]),\n",
      "  target=(y=[b=32, t=24, n=6, f=1]),\n",
      "  has_mask=True\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train):\n",
    "    print(i, batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "it = iter(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "StaticBatch(\n  input=(x=[b=32, t=24, n=6, f=1], input_mask=[b=32, t=24, n=6, f=1], edge_index=[2, e=36], edge_weight=[e=36]),\n  target=(y=[b=32, t=24, n=6, f=1]),\n  has_mask=True\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.6713],\n         [0.7015],\n         [0.1856],\n         [0.0351],\n         [0.5445],\n         [0.5789]],\n\n        [[0.7011],\n         [0.7252],\n         [0.2199],\n         [0.0311],\n         [0.4819],\n         [0.0000]],\n\n        [[0.7165],\n         [0.7649],\n         [0.2206],\n         [0.0328],\n         [0.4439],\n         [0.0000]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.input.x[0,:3,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True]],\n\n        [[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [False]],\n\n        [[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [False]]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target.y[0,0:3,:] == batch.input.x[0,0:3,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True]],\n\n        [[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [False]],\n\n        [[ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True],\n         [ True]]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.input.input_mask[0,0:3,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([36])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.input.edge_weight.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'input_size':dm.n_channels,\n",
    "    'n_nodes':dm.n_nodes,\n",
    "    'hidden_size': 64,\n",
    "    'ff_size': 64,\n",
    "    'embedding_size': 8,\n",
    "    'n_layers': 1,\n",
    "    'kernel_size': 2,\n",
    "    'decoder_order': 1,\n",
    "    'layer_norm': False,\n",
    "    'dropout': 0,\n",
    "    'ff_dropout': 0,\n",
    "    'merge_mode': 'mlp'}\n",
    "\n",
    "from tsl.metrics.torch import MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Imputer\n",
    "from tsl.nn.models import GRINModel\n",
    "\n",
    "optim_kwargs = {'lr': 0.001, 'weight_decay': 0}\n",
    "scheduler_kwargs = {'eta_min': 0.0001, 'T_max': 300}\n",
    "loss_fn = MaskedMAE()\n",
    "log_metrics = {'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE(),}\n",
    "\n",
    "imputer = Imputer(\n",
    "    model_class=GRINModel,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs=optim_kwargs,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=log_metrics,\n",
    "    scheduler_class=torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "    scheduler_kwargs=scheduler_kwargs,\n",
    "    whiten_prob=0.05,\n",
    "    prediction_loss_weight=1.0,\n",
    "    impute_only_missing=False,\n",
    "    warm_up_steps=0,\n",
    "    #\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "y = imputer(\n",
    "    x=batch.input.x,\n",
    "    edge_index=batch.input.edge_index,\n",
    "    edge_weight=batch.input.edge_weight,\n",
    "    input_mask=batch.input.input_mask,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 24, 6, 1])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = y[0]\n",
    "prediction.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "fwd_out, bwd_out, fwd_pred, bwd_pred = y[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24, 6, 1]) torch.Size([32, 24, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(fwd_out.shape,fwd_pred.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
